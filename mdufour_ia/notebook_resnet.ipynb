{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, datetime, shutil, os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 100\n",
    "IMG_WIDTH = 96\n",
    "IMG_HEIGHT = 96\n",
    "TRAIN_DATA_PATH = 'chest_xray/train'\n",
    "TEST_DATA_PATH = 'chest_xray/test'\n",
    "VAL_DATA_PATH = 'chest_xray/val'\n",
    "CLASS_NAMES = ['NORMAL', 'BACTERIA', 'VIRUS']\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "VERBOSE = 1\n",
    "MODEL_NAME = 'resnet_18'\n",
    "\n",
    "METRICS = [\n",
    "  tf.keras.metrics.BinaryAccuracy(name='accuracy', dtype=tf.float32),\n",
    "  tf.keras.metrics.TruePositives(name='true_positives', dtype=tf.float32),\n",
    "  tf.keras.metrics.FalsePositives(name='false_positives', dtype=tf.float32),\n",
    "  tf.keras.metrics.TrueNegatives(name='true_negatives', dtype=tf.float32),\n",
    "  tf.keras.metrics.FalseNegatives(name='false_negatives', dtype=tf.float32), \n",
    "  tf.keras.metrics.Precision(name='precision', dtype=tf.float32),\n",
    "  tf.keras.metrics.Recall(name='recall', dtype=tf.float32),\n",
    "  tf.keras.metrics.AUC(name='auc', dtype=tf.float32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model=None, model_name='vgg16'):\n",
    "  \"\"\"\n",
    "  Save a TF Model into h5 format\n",
    "  \"\"\"\n",
    "  model.save('saved_model/{}/model.h5'.format(model_name))\n",
    "  print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "  \"\"\"\n",
    "  Define the callbacks for the ML model\n",
    "  \"\"\"\n",
    "  return [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10),\n",
    "    tf.keras.callbacks.TensorBoard(os.path.join(\"logs/{}\".format('resnet_18'), datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")), histogram_freq=1)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  \"\"\"\n",
    "  Get the label of a file - Can be NORMAL or PNEUMONIA\n",
    "  \"\"\"\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  \"\"\"\n",
    "  Convert an image into a tensor with needed size\n",
    "  \"\"\"\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  \"\"\"\n",
    "  Process a file\n",
    "  \"\"\"\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(layers.Layer):\n",
    "  \"\"\"\n",
    "  BasicBlock class\n",
    "  \"\"\"\n",
    "  def __init__(self, filter_num, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv_b_1 = layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=stride, padding='same')\n",
    "    self.bn_b_1 = layers.BatchNormalization()\n",
    "    self.conv_b_2 = layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=1, padding='same')\n",
    "    self.bn_b_2 = layers.BatchNormalization()\n",
    "    if stride != 1:\n",
    "      self.downsample = tf.keras.Sequential()\n",
    "      self.downsample.add(layers.Conv2D(filters=filter_num, kernel_size=(1, 1), strides=stride))\n",
    "      self.downsample.add(layers.BatchNormalization())\n",
    "    else:\n",
    "      self.downsample = lambda x: x\n",
    "\n",
    "  def call(self, inputs, **kwargs):\n",
    "    residual = self.downsample(inputs)\n",
    "    x = self.conv_b_1(inputs)\n",
    "    x = self.bn_b_1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.conv_b_2(x)\n",
    "    x = self.bn_b_2(x)\n",
    "    # print(residual)\n",
    "    output = tf.nn.relu(x)\n",
    "    return output\n",
    "\n",
    "\n",
    "class BottleNeck(layers.Layer):\n",
    "  \"\"\"\n",
    "  Bottleneck class\n",
    "  \"\"\"\n",
    "  def __init__(self, filter_num, stride=1):\n",
    "    super(BottleNeck, self).__init__()\n",
    "    self.conv_b_1 = layers.Conv2D(filters=filter_num, kernel_size=(1, 1), strides=1, padding='same')\n",
    "    self.bn_b_1 = layers.BatchNormalization()\n",
    "    self.conv_b_2 = layers.Conv2D(filters=filter_num, kernel_size=(3, 3), strides=stride, padding='same')\n",
    "    self.bn_b_2 = layers.BatchNormalization()\n",
    "    self.conv_b_3 = layers.Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=1, padding='same')\n",
    "    self.bn_b_3 = layers.BatchNormalization()\n",
    "\n",
    "    self.downsample = tf.keras.Sequential()\n",
    "    self.downsample.add(layers.Conv2D(filters=filter_num * 4, kernel_size=(1, 1), strides=stride))\n",
    "    self.downsample.add(layers.BatchNormalization())\n",
    "\n",
    "  def call(self, inputs, **kwargs):\n",
    "    residual = self.downsample(inputs)\n",
    "    x = self.conv_b_1(inputs)\n",
    "    x = self.bn_b_1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.conv_b_2(x)\n",
    "    x = self.bn_b_2(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.conv_b_3(x)\n",
    "    x = self.bn_b_3(x)\n",
    "    output = tf.nn.relu(layers.add([residual, x]))\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
    "  \"\"\"\n",
    "  Generate a block layer\n",
    "  \"\"\"\n",
    "  res_block = tf.keras.Sequential()\n",
    "  res_block.add(BasicBlock(filter_num, stride=stride))\n",
    "\n",
    "  for _ in range(1, blocks):\n",
    "    res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "  return res_block\n",
    "\n",
    "\n",
    "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
    "  \"\"\"\n",
    "  Generate a bottleneck layer\n",
    "  \"\"\"\n",
    "  res_block = tf.keras.Sequential()\n",
    "  res_block.add(BottleNeck(filter_num, stride=stride))\n",
    "\n",
    "  for _ in range(1, blocks):\n",
    "    res_block.add(BottleNeck(filter_num, stride=1))\n",
    "\n",
    "  return res_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "\n",
    "class ResNetTypeI(tf.keras.Model):\n",
    "  \"\"\"\n",
    "  A ResNetTypeI Model - Use of basic bloc layers (conv2D + batch normalization + conv2D + batch normalization)\n",
    "  \"\"\"\n",
    "  def __init__(self, nodes, name=None, final_activation='softmax'):\n",
    "    super(ResNetTypeI, self).__init__(name=name)\n",
    "    # first conv\n",
    "    self.conv_1 = layers.Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH , 3), strides=2)\n",
    "    # batch normalization\n",
    "    self.bn_1 = layers.BatchNormalization()\n",
    "    # pooling\n",
    "    self.pooling_1 = layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')\n",
    "    # basic block layers\n",
    "    self.layer_1 = make_basic_block_layer(filter_num=64, blocks=nodes[0])\n",
    "    self.layer_2 = make_basic_block_layer(filter_num=128, blocks=nodes[1], stride=2)\n",
    "    self.layer_3 = make_basic_block_layer(filter_num=256, blocks=nodes[2], stride=2)\n",
    "    self.layer_4 = make_basic_block_layer(filter_num=512, blocks=nodes[3], stride=2)\n",
    "    # global average pool\n",
    "    self.avg_pool = layers.GlobalAveragePooling2D()\n",
    "    # prediction\n",
    "    self.pred_layer = layers.Dense(units=NUM_CLASSES, activation=final_activation, name='predictions')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.bn_1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.pooling_1(x)\n",
    "    x = self.layer_1(x)\n",
    "    x = self.layer_2(x)\n",
    "    x = self.layer_3(x)\n",
    "    x = self.layer_4(x)\n",
    "    x = self.avg_pool(x)\n",
    "    return self.pred_layer(x)\n",
    "\n",
    "class ResNetTypeII(tf.keras.Model):\n",
    "  \"\"\"\n",
    "  A ResNetTypeII Model - Use of bottleneck layers (conv2D + batch normalization + conv2D + batch normalization)\n",
    "  \"\"\"\n",
    "  def __init__(self, nodes, name=None, final_activation='softmax'):\n",
    "    super(ResNetTypeII, self).__init__(name=name)\n",
    "    # first conv\n",
    "    self.conv_1 = layers.Conv2D(16, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH , 3), strides=2)\n",
    "    # batch normalization\n",
    "    self.bn_1 = layers.BatchNormalization()\n",
    "    # pooling\n",
    "    self.pooling_1 = layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')\n",
    "    # basic block layers\n",
    "    self.layer_1 = make_bottleneck_layer(filter_num=64, blocks=nodes[0])\n",
    "    self.layer_2 = make_bottleneck_layer(filter_num=128, blocks=nodes[1], stride=2)\n",
    "    self.layer_3 = make_bottleneck_layer(filter_num=256, blocks=nodes[2], stride=2)\n",
    "    self.layer_4 = make_bottleneck_layer(filter_num=512, blocks=nodes[3], stride=2)\n",
    "    # global average pool\n",
    "    self.avg_pool = layers.GlobalAveragePooling2D()\n",
    "    # prediction\n",
    "    self.pred_layer = layers.Dense(units=NUM_CLASSES, activation=final_activation, name='predictions')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.bn_1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = self.pooling_1(x)\n",
    "    x = self.layer_1(x)\n",
    "    x = self.layer_2(x)\n",
    "    x = self.layer_3(x)\n",
    "    x = self.layer_4(x)\n",
    "    x = self.avg_pool(x)\n",
    "    return self.pred_layer(x)\n",
    "\n",
    "def get_model_resnet(model='resnet_18', optimizer='adam', loss='binary_crossentropy', final_activation='softmax', metrics='accuracy'):\n",
    "  \"\"\"\n",
    "  Return a basic model\n",
    "  \"\"\"\n",
    "  if model == 'resnet_18':\n",
    "    model = resnet_18(final_activation=final_activation)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "    return model\n",
    "  elif model == 'resnet_34':\n",
    "    model = resnet_34(final_activation=final_activation)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def resnet_18(final_activation):\n",
    "    return ResNetTypeI(nodes=[2, 2, 2, 2], name='resnet1_18', final_activation=final_activation)\n",
    "\n",
    "\n",
    "def resnet_34(final_activation):\n",
    "    return ResNetTypeI(nodes=[3, 4, 6, 3], name='resnet1_34', final_activation=final_activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main function\n",
    "\"\"\"\n",
    "modelLoaded = False\n",
    "model = None\n",
    "# if the model already exist, load it.\n",
    "if (os.path.isfile('saved_model/{}/model.h5'.format(MODEL_NAME))):\n",
    "    model = tf.keras.models.load_model('saved_model/{}/model.h5'.format(MODEL_NAME))\n",
    "    modelLoaded = True\n",
    "    print('Model successfully loaded.')\n",
    "else:\n",
    "    # Get the model\n",
    "    # model = get_model_vgg(\n",
    "    #   model=MODEL_NAME,\n",
    "    #   nodes=16,\n",
    "    #   optimizer='adam',\n",
    "    #   loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    #   hidden_activation='relu',\n",
    "    #   final_activation='sigmoid',\n",
    "    #   metrics=None\n",
    "    # )\n",
    "    model = get_model_resnet(\n",
    "        model=MODEL_NAME,\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        final_activation='softmax',\n",
    "        metrics=None\n",
    "    )\n",
    "\n",
    "# To get the nb of steps and how many images we got\n",
    "nb_normal_tr = len(os.listdir('{}/NORMAL'.format(TRAIN_DATA_PATH)))\n",
    "nb_bacteria_tr = len(os.listdir('{}/BACTERIA'.format(TRAIN_DATA_PATH)))\n",
    "nb_virus_tr = len(os.listdir('{}/VIRUS'.format(TRAIN_DATA_PATH)))\n",
    "nb_normal_val = len(os.listdir('{}/NORMAL'.format(VAL_DATA_PATH)))\n",
    "nb_bacteria_val = len(os.listdir('{}/BACTERIA'.format(VAL_DATA_PATH)))\n",
    "nb_virus_val = len(os.listdir('{}/VIRUS'.format(VAL_DATA_PATH)))\n",
    "total_train = nb_normal_tr + nb_bacteria_tr + nb_virus_tr\n",
    "total_val = nb_normal_val + nb_bacteria_val + nb_virus_val\n",
    "\n",
    "# Our datas generators\n",
    "train_image_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.5\n",
    ")\n",
    "# Generator for our training data\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=TRAIN_DATA_PATH,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=VAL_DATA_PATH,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "test_data_gen = test_image_generator.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=TEST_DATA_PATH,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_data_gen,\n",
    "    callbacks=get_callbacks(),\n",
    "    steps_per_epoch=total_train // BATCH_SIZE,\n",
    "    epochs=NB_EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // BATCH_SIZE\n",
    ")\n",
    "save_model(model, 'resnet_18')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Use a testing model to display metrics\n",
    "testing_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "testing_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer='adam',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# Display metrics for testing purpose\n",
    "print('Normal, Virus or Bacteria resnet 18 trained model : ')\n",
    "results = testing_model.evaluate(test_data_gen)\n",
    "for name, value in zip(testing_model.metrics_names, results):\n",
    "    print(f'{name} : {value}')\n",
    "\n",
    "# predictions\n",
    "predictions = testing_model.predict(test_data_gen)\n",
    "for predict in predictions:\n",
    "    print('Predictions : ', predict)"
   ]
  }
 ]
}